{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/trimcao/Dropbox/Richardson/Fall-2017/cs6375-ml-ruozzi/solution/lib')\n",
    "sys.path.insert(0, '/home/trimcao/Dropbox/Richardson/Fall-2017/cs6375-ml-ruozzi/solution/lib')\n",
    "from importlib import reload\n",
    "# using reload to avoid having to restart the Python kernel after modifying source code\n",
    "import NaiveBayes; reload(NaiveBayes)\n",
    "from NaiveBayes import MultinomialNB, MixtureNB, MixtureNBDirichlet\n",
    "from scipy.stats import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            info = line.strip('\\n').split(',')\n",
    "            # label is the first column\n",
    "            X.append(info[1])\n",
    "            y.append(info[0])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X, y):\n",
    "    \"\"\"\n",
    "    Convert text strings to a data matrix of numbers.\n",
    "    \"\"\"\n",
    "    random.seed(0) # choose a seed so I can reproduce the results\n",
    "    label2int = {label:i for i, label in enumerate(set(y))}\n",
    "    int2label = {i:label for i, label in enumerate(set(y))}\n",
    "    chars = {'A', 'G', 'T', 'C'}\n",
    "    char2int = {char:i for i, char in enumerate(chars)}\n",
    "    int2char = {i:char for i, char in enumerate(chars)}\n",
    "    counts = {i:0 for i in int2char}\n",
    "    # feature matrix\n",
    "    data_matrix = np.zeros((len(X), len(chars)))\n",
    "    for i in range(data_matrix.shape[0]):\n",
    "        string = X[i].split()[0]\n",
    "        for char in string:\n",
    "            if char == 'D':\n",
    "                char = random.choice(['A', 'G', 'T'])\n",
    "            elif char == 'N':\n",
    "                char = random.choice(['A', 'G', 'C', 'T'])\n",
    "                # print(char)\n",
    "            elif char == 'S':\n",
    "                char = random.choice(['C', 'G'])\n",
    "            elif char == 'R':\n",
    "                char = random.choice(['A', 'G'])\n",
    "            data_matrix[i, char2int[char]] += 1\n",
    "    # label vector\n",
    "    labels = np.zeros((len(y),))\n",
    "    for i in range(labels.shape[0]):\n",
    "        labels[i] = label2int[y[i]]\n",
    "    return data_matrix, labels, label2int, int2label, char2int, int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_in('hw4_data/bio.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, label2int, int2label, char2int, int2char = preprocess(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Multinomial NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263322884012539"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X)\n",
    "np.mean(preds==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather the data\n",
    "X_train = X[:2126]\n",
    "y_train = y[:2126]\n",
    "X_test = X[2126:]\n",
    "y_test = y[2126:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 5 # number of NB models\n",
    "L = 3 # number of different labels\n",
    "D = 4 # number of features\n",
    "N = X_train.shape[0] # number of training samples\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "[-1.43156228 -2.97738535 -1.24658236 -1.21156418 -2.08006585]\n",
      "iteration 50\n",
      "[-1.42750475 -1.6528797  -2.04554912 -1.53876251 -1.49325698]\n",
      "iteration 100\n",
      "[-1.64871911 -1.46614275 -2.10439881 -1.47529213 -1.48607487]\n",
      "iteration 150\n",
      "[-1.70886814 -1.42725948 -2.2083292  -1.48988034 -1.41189935]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55263157894736847"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "clf = MixtureNB(K, L, D)\n",
    "for i in range(200):\n",
    "    clf.em(X_train, y_train)\n",
    "    if i % 50 == 0:\n",
    "        print('iteration', i)\n",
    "        print(clf.p_z)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# test new Dirichlet naive bayes\n",
    "num_iter = 200\n",
    "clf = MixtureNBDirichlet(K=5, L=3, D=4)\n",
    "for i in range(num_iter):\n",
    "    clf.em(X_train, y_train)\n",
    "    if i % 10 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51973684210526316"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(K=5, L=3, D=4):\n",
    "    \"\"\"\n",
    "    k: number of NB models\n",
    "    D: number of features\n",
    "    L: number of different labels\n",
    "    \"\"\"\n",
    "    models = [MultinomialNB() for i in range(K)]\n",
    "    for i in range(K):\n",
    "        p_y = np.random.random(L)\n",
    "        p_y = np.log(p_y / p_y.sum())\n",
    "        models[i].prob_y = p_y\n",
    "        p_x_given_y = np.random.random((L,D))\n",
    "        for j in range(L):\n",
    "            p_x_given_y[j] /= p_x_given_y[j].sum()\n",
    "        models[i].prob_x_given_y = np.log(p_x_given_y)\n",
    "    # initialize lambda z\n",
    "    p_z = np.random.random(K)\n",
    "    p_z = p_z / p_z.sum()\n",
    "    p_z = np.log(p_z)\n",
    "    return models, p_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def em(X_train, y_train, models, p_z, L=3, D=4):\n",
    "    \"\"\"\n",
    "    EM algorithm for Mixture of Naive Bayes models.\n",
    "    \"\"\"\n",
    "    N = X_train.shape[0] # number of training samples \n",
    "    K = len(models)\n",
    "    \n",
    "    # E-step, update Qi(z)\n",
    "    q_z = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            # update q_z for sample i and NB model j\n",
    "            q_z[i,j] = p_z[j] + models[j].log_prob_x_y(X_train[i],y_train[i])\n",
    "        # normalize q_z[i], then take log\n",
    "        q_z[i] = np.exp(q_z[i])\n",
    "        q_z[i] = np.log(q_z[i] / q_z[i].sum())\n",
    "    # M-step, update parameters in each model\n",
    "    # k = NB model number\n",
    "    # l = value of y\n",
    "    # d = value of x\n",
    "\n",
    "    # NOTE: keep q_z and p_z to be probability, not log probability\n",
    "    # calculate the p_y as probabilty for each model, only calculate the log \n",
    "    # at the end\n",
    "    q_z_nonlog = np.exp(q_z)\n",
    "    p_z = np.sum(q_z_nonlog, axis=0)\n",
    "    for k in range(K):\n",
    "        # build the mttrix q_z[k] * X_train\n",
    "        X_q = np.tile(q_z_nonlog[:,k], (D,1)).T * X_train\n",
    "        # q_z_nonlog for z = l\n",
    "        q_k = q_z_nonlog[:,k]\n",
    "        p_k = p_z[k]\n",
    "        models[k].prob_y = np.zeros(L)\n",
    "        models[k].prob_x_given_y = np.zeros((L,D))\n",
    "        for l in range(L):\n",
    "            # matrix q_z for the rows when y == l\n",
    "            models[k].prob_y[l] = np.log(q_k[y_train==l].sum() / p_z[k])\n",
    "            # update P(x|y) for each model\n",
    "            X_l = X_q[y_train==l] # part of X_q that has y == l\n",
    "            models[k].prob_x_given_y[l] = np.log(X_l.sum(axis=0) / X_l.sum())        \n",
    "    # divide p_z by N\n",
    "    p_z = np.log(p_z / N)\n",
    "    return models, q_z, p_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's next:\n",
    "- Combine the EM steps to make a training function\n",
    "- How to check for convergence\n",
    "- Prediction\n",
    "- Test the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test EM algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models, p_z = initialize(K=5, L=3, D=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.37845213, -3.83925239, -0.12126818])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].prob_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.48220488, -1.37062569, -1.25299114, -1.45557348],\n",
       "       [-1.46656711, -0.94103233, -2.82799688, -1.13965968],\n",
       "       [-2.64778195, -0.76225956, -1.3557171 , -1.58563049]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].prob_x_given_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "[-1.43156228 -2.97738535 -1.24658236 -1.21156418 -2.08006585]\n",
      "iteration 50\n",
      "[-1.42750475 -1.6528797  -2.04554912 -1.53876251 -1.49325698]\n",
      "iteration 100\n",
      "[-1.64871911 -1.46614275 -2.10439881 -1.47529213 -1.48607487]\n",
      "iteration 150\n",
      "[-1.70886814 -1.42725948 -2.2083292  -1.48988034 -1.41189935]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    models, q_z, p_z = em(X_train, y_train, models, p_z)\n",
    "    if i % 50 == 0:\n",
    "        print('iteration', i)\n",
    "        print(p_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20289666, -2.00499454, -3.0164174 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].prob_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66554019, -1.08871828, -1.49101687, -1.38981973],\n",
       "       [-1.09691085, -2.01982143, -1.95988956, -0.9351018 ],\n",
       "       [-2.07750529, -1.13208376, -1.10667195, -1.50625281]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].prob_x_given_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.791748   -1.85833596 -2.28992597 -1.19878837 -1.29256288]\n"
     ]
    }
   ],
   "source": [
    "print(p_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_prob_log(X, K=5):\n",
    "    probs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        prob = None\n",
    "        for k in range(K):\n",
    "            _, predict_prob = models[k].predict_single(X[i])\n",
    "            if prob is None:\n",
    "                prob = np.exp(predict_prob) * np.exp(p_z[k])\n",
    "            else:\n",
    "                prob += np.exp(predict_prob) * np.exp(p_z[k])\n",
    "            # print(prob)\n",
    "        probs.append(prob)\n",
    "    return np.log(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-83.13788439, -83.69393242, -84.26781131],\n",
       "       [-84.08328226, -83.98040351, -84.96280829]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob_log(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, K=5):\n",
    "    preds_prob = predict_prob_log(X)\n",
    "    return np.argmax(preds_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385338345864662"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(X_test)\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 10 times running EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start EM number 0\n",
      "finish EM.\n",
      "Train accuracy: 0.53809971778\n",
      "Test accuracy: 0.522556390977\n",
      "\n",
      "start EM number 1\n",
      "finish EM.\n",
      "Train accuracy: 0.541392285983\n",
      "Test accuracy: 0.527255639098\n",
      "\n",
      "start EM number 2\n",
      "finish EM.\n",
      "Train accuracy: 0.554562558796\n",
      "Test accuracy: 0.548872180451\n",
      "\n",
      "start EM number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trimcao/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/trimcao/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "/home/trimcao/Dropbox/Richardson/Fall-2017/cs6375-ml-ruozzi/solution/lib/NaiveBayes.py:113: RuntimeWarning: invalid value encountered in multiply\n",
      "  log_prob = (x * self.prob_x_given_y[y]).sum() + self.prob_y[y]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish EM.\n",
      "Train accuracy: 0.50987770461\n",
      "Test accuracy: 0.536654135338\n",
      "\n",
      "start EM number 4\n",
      "finish EM.\n",
      "Train accuracy: 0.56020696143\n",
      "Test accuracy: 0.536654135338\n",
      "\n",
      "start EM number 5\n",
      "finish EM.\n",
      "Train accuracy: 0.555032925682\n",
      "Test accuracy: 0.552631578947\n",
      "\n",
      "start EM number 6\n",
      "finish EM.\n",
      "Train accuracy: 0.542803386642\n",
      "Test accuracy: 0.536654135338\n",
      "\n",
      "start EM number 7\n",
      "finish EM.\n",
      "Train accuracy: 0.540451552211\n",
      "Test accuracy: 0.523496240602\n",
      "\n",
      "start EM number 8\n",
      "finish EM.\n",
      "Train accuracy: 0.547507055503\n",
      "Test accuracy: 0.547932330827\n",
      "\n",
      "start EM number 9\n",
      "finish EM.\n",
      "Train accuracy: 0.55409219191\n",
      "Test accuracy: 0.546052631579\n",
      "\n",
      "Average accuracy on training set: 0.544402634055\n",
      "Average accuracy on test set: 0.53787593985\n"
     ]
    }
   ],
   "source": [
    "num_iter = 200\n",
    "acc_train = 0\n",
    "acc_test = 0\n",
    "for m in range(10):\n",
    "    print('start EM number', m)\n",
    "    np.random.seed(m+10)\n",
    "    models, p_z = initialize(K=5, L=3, D=4)\n",
    "    for i in range(num_iter):\n",
    "        models, q_z, p_z = em(X_train, y_train, models, p_z)\n",
    "    print('finish EM.')\n",
    "    train_preds = predict(X_train)\n",
    "    test_preds = predict(X_test)\n",
    "    acc_train += np.mean(train_preds==y_train)\n",
    "    acc_test += np.mean(test_preds==y_test)    \n",
    "    print('Train accuracy:', np.mean(train_preds==y_train))\n",
    "    print('Test accuracy:', np.mean(test_preds==y_test))\n",
    "    print()\n",
    "    \n",
    "print('Average accuracy on training set:', acc_train/10)\n",
    "print('Average accuracy on test set:', acc_test/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### EM with Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_dirichlet(K=5, L=3, D=4):\n",
    "    \"\"\"\n",
    "    k: number of NB models\n",
    "    D: number of features\n",
    "    L: number of different labels\n",
    "    \"\"\"\n",
    "    models = [MultinomialNB() for i in range(K)]\n",
    "    for i in range(K):\n",
    "        models[i].prob_y = dirichlet([2]*L)\n",
    "        # create the dirichlet distribution individually so I have\n",
    "        # separate scipy.stats.dirichlet objects (and I can change\n",
    "        # them later).\n",
    "        prob_x_given_y = []\n",
    "        for j in range(L):\n",
    "            prob_x_given_y.append(dirichlet([2]*D))\n",
    "#         models[i].prob_x_given_y = [dirichlet([2]*D)]*L\n",
    "        models[i].prob_x_given_y = prob_x_given_y\n",
    "    # initialize lambda z\n",
    "    p_z = np.random.random(K)\n",
    "    p_z = p_z / p_z.sum()\n",
    "    p_z = np.log(p_z)\n",
    "    return models, p_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def em_dirichlet(X_train, y_train, models, p_z, L=3, D=4):\n",
    "    \"\"\"\n",
    "    EM algorithm for Mixture of Naive Bayes models.\n",
    "    \"\"\"\n",
    "    N = X_train.shape[0] # number of training samples \n",
    "    K = len(models)\n",
    "    \n",
    "    # E-step, update Qi(z)\n",
    "    q_z = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            # update q_z for sample i and NB model j\n",
    "            q_z[i,j] = p_z[j] + models[j].log_prob_x_y_dirichlet(X_train[i],y_train[i])\n",
    "        # normalize q_z[i], then take log\n",
    "        q_z[i] = np.exp(q_z[i])\n",
    "        q_z[i] = np.log(q_z[i] / q_z[i].sum())\n",
    "        \n",
    "    # M-step, update parameters in each model\n",
    "    # k = NB model number\n",
    "    # l = value of y\n",
    "    # d = value of x\n",
    "\n",
    "    # NOTE: keep q_z and p_z to be probability, not log probability\n",
    "    # calculate the p_y as probabilty for each model, only calculate the log \n",
    "    # at the end\n",
    "    q_z_nonlog = np.exp(q_z)\n",
    "    p_z = np.sum(q_z_nonlog, axis=0)\n",
    "    for k in range(K):\n",
    "        # build the mttrix q_z[k] * X_train\n",
    "        X_q = np.tile(q_z_nonlog[:,k], (D,1)).T * X_train\n",
    "        # q_z_nonlog for z = l\n",
    "        q_k = q_z_nonlog[:,k]\n",
    "        p_k = p_z[k]\n",
    "        # models[k].prob_y = np.zeros(L)\n",
    "        # models[k].prob_x_given_y = np.zeros((L,D))\n",
    "        for l in range(L):\n",
    "            # matrix q_z for the rows when y == l\n",
    "            # models[k].prob_y.alpha[l] = np.int(q_k[y_train==l].sum())\n",
    "            models[k].prob_y.alpha[l] += np.int(q_k[y_train==l].sum())\n",
    "            # update P(x|y) for each model\n",
    "            X_l = X_q[y_train==l] # part of X_q that has y == l\n",
    "            # print(X_l.sum(axis=0))\n",
    "            # print(X_l.sum(axis=0).astype(np.int64))\n",
    "            # models[k].prob_x_given_y[l].alpha = X_l.sum(axis=0).astype(np.int64)\n",
    "            models[k].prob_x_given_y[l].alpha += X_l.sum(axis=0).astype(np.int64)\n",
    "    # divide p_z by N\n",
    "    p_z = np.log(p_z / N)\n",
    "    return models, q_z, p_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start EM number 1\n",
      "0\n",
      "[-1.64887203 -1.44873541 -1.54561853 -1.61164416 -1.8317879 ]\n",
      "[104 201 101]\n",
      "[1419 1261 1599 2018]\n",
      "\n",
      "50\n",
      "[-1.60852164 -1.46430882 -1.52467218 -1.64719095 -1.84328641]\n",
      "[102 217 105]\n",
      "[1374 1250 1613 1925]\n",
      "\n",
      "100\n",
      "[-1.58897832 -1.4730118  -1.52637274 -1.68021009 -1.81416123]\n",
      "[104 221 108]\n",
      "[1397 1273 1638 1953]\n",
      "\n",
      "150\n",
      "[-1.58950314 -1.51938611 -1.51576935 -1.67947996 -1.76599358]\n",
      "[105 220 107]\n",
      "[1410 1283 1654 1985]\n",
      "\n",
      "200\n",
      "[-1.60682987 -1.52179235 -1.50873987 -1.67337562 -1.75819163]\n",
      "[103 217 105]\n",
      "[1379 1259 1624 1933]\n",
      "\n",
      "250\n",
      "[-1.60955387 -1.56197539 -1.49667903 -1.68684157 -1.70745781]\n",
      "[101 217 105]\n",
      "[1364 1245 1603 1906]\n",
      "\n",
      "300\n",
      "[-1.62287366 -1.56671507 -1.52921972 -1.65799161 -1.67817978]\n",
      "[101 214 103]\n",
      "[1353 1237 1591 1893]\n",
      "\n",
      "350\n",
      "[-1.6542578  -1.5969406  -1.52178872 -1.61632879 -1.66440462]\n",
      "[ 98 207 100]\n",
      "[1320 1202 1550 1849]\n",
      "\n",
      "400\n",
      "[-1.65678781 -1.60177321 -1.53453543 -1.59136418 -1.66862   ]\n",
      "[ 97 207 100]\n",
      "[1308 1192 1537 1833]\n",
      "\n",
      "450\n",
      "[-1.64837321 -1.61822944 -1.56335148 -1.57161408 -1.64898272]\n",
      "[ 98 208 102]\n",
      "[1319 1205 1550 1842]\n",
      "\n",
      "500\n",
      "[-1.6613644  -1.6054129  -1.592789   -1.57079758 -1.61910109]\n",
      "[ 97 206 100]\n",
      "[1298 1187 1529 1812]\n",
      "\n",
      "550\n",
      "[-1.71802401 -1.58454784 -1.59858976 -1.54621512 -1.6079145 ]\n",
      "[ 92 194  94]\n",
      "[1232 1126 1448 1723]\n",
      "\n",
      "600\n",
      "[-1.68324075 -1.5674716  -1.61516456 -1.58918819 -1.59598878]\n",
      "[ 95 200  98]\n",
      "[1277 1166 1500 1789]\n",
      "\n",
      "650\n",
      "[-1.68051249 -1.5430349  -1.62729764 -1.58999703 -1.61141951]\n",
      "[ 95 201  98]\n",
      "[1279 1165 1499 1787]\n",
      "\n",
      "700\n",
      "[-1.69028853 -1.57734382 -1.60271322 -1.57028537 -1.61106181]\n",
      "[ 94 199  97]\n",
      "[1270 1156 1488 1780]\n",
      "\n",
      "750\n",
      "[-1.67823679 -1.62506012 -1.57054432 -1.58162872 -1.5954097 ]\n",
      "[ 96 202  98]\n",
      "[1286 1170 1509 1798]\n",
      "\n",
      "800\n",
      "[-1.69797405 -1.60699249 -1.5923705  -1.57786868 -1.57697572]\n",
      "[ 94 197  97]\n",
      "[1260 1146 1475 1766]\n",
      "\n",
      "850\n",
      "[-1.65301095 -1.64262147 -1.6446939  -1.5735489  -1.53862785]\n",
      "[ 98 207 100]\n",
      "[1316 1202 1543 1842]\n",
      "\n",
      "900\n",
      "[-1.61964008 -1.65249807 -1.66565669 -1.56590446 -1.54884218]\n",
      "[101 212 106]\n",
      "[1360 1238 1594 1905]\n",
      "\n",
      "950\n",
      "[-1.63841877 -1.60880212 -1.65746305 -1.60565273 -1.54082013]\n",
      "[ 99 211 102]\n",
      "[1334 1213 1562 1871]\n",
      "\n",
      "finish EM.\n"
     ]
    }
   ],
   "source": [
    "# test EM algorithm with Dirichlet distribution\n",
    "num_iter = 1000\n",
    "print('start EM number', 1)\n",
    "np.random.seed(0)\n",
    "models, p_z = initialize_dirichlet(K=5, L=3, D=4)\n",
    "for i in range(num_iter):\n",
    "    models, q_z, p_z = em_dirichlet(X_train, y_train, models, p_z)\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "        print(p_z)\n",
    "        print(models[0].prob_y.alpha)\n",
    "        print(models[0].prob_x_given_y[0].alpha)\n",
    "        print()\n",
    "print('finish EM.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.64207738, -1.60597727, -1.63509683, -1.58770854, -1.57792833])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[-1.79174801 -1.85833594 -2.28992598 -1.19878836 -1.29256288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_prob_log_dirichlet(X, K=5):\n",
    "    probs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        prob = None\n",
    "        for k in range(K):\n",
    "            _, predict_prob = models[k].predict_single_dirichlet(X[i])\n",
    "            if prob is None:\n",
    "                prob = np.exp(predict_prob) * np.exp(p_z[k])\n",
    "            else:\n",
    "                prob += np.exp(predict_prob) * np.exp(p_z[k])\n",
    "            # print(prob)\n",
    "        probs.append(prob)\n",
    "    return np.log(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_dirichlet(X, K=5):\n",
    "    preds_prob = predict_prob_log_dirichlet(X)\n",
    "    return np.argmax(preds_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.24369977,  21.50989469,  21.25596562],\n",
       "       [  8.25809567,   8.51072578,   8.24030257],\n",
       "       [ 17.24715383,  17.5006175 ,  17.24148748],\n",
       "       [ 14.24876503,  14.50583837,  14.24863845]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob_log_dirichlet(X_test[1],K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51221804511278191"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict_dirichlet(X_test, K=5)\n",
    "np.mean(preds==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 10 times running EM with Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start EM number 0\n",
      "finish EM.\n",
      "Train accuracy: 0.498118532455\n",
      "Test accuracy: 0.513157894737\n",
      "\n",
      "start EM number 1\n",
      "finish EM.\n",
      "Train accuracy: 0.505174035748\n",
      "Test accuracy: 0.516917293233\n",
      "\n",
      "start EM number 2\n",
      "finish EM.\n",
      "Train accuracy: 0.507996237065\n",
      "Test accuracy: 0.523496240602\n",
      "\n",
      "start EM number 3\n",
      "finish EM.\n",
      "Train accuracy: 0.504233301976\n",
      "Test accuracy: 0.515977443609\n",
      "\n",
      "start EM number 4\n",
      "finish EM.\n",
      "Train accuracy: 0.501881467545\n",
      "Test accuracy: 0.520676691729\n",
      "\n",
      "start EM number 5\n",
      "finish EM.\n",
      "Train accuracy: 0.503762935089\n",
      "Test accuracy: 0.518796992481\n",
      "\n",
      "start EM number 6\n",
      "finish EM.\n",
      "Train accuracy: 0.50611476952\n",
      "Test accuracy: 0.515037593985\n",
      "\n",
      "start EM number 7\n",
      "finish EM.\n",
      "Train accuracy: 0.508936970837\n",
      "Test accuracy: 0.513157894737\n",
      "\n",
      "start EM number 8\n",
      "finish EM.\n",
      "Train accuracy: 0.50611476952\n",
      "Test accuracy: 0.510338345865\n",
      "\n",
      "start EM number 9\n",
      "finish EM.\n",
      "Train accuracy: 0.503762935089\n",
      "Test accuracy: 0.515037593985\n",
      "\n",
      "Average accuracy on training set: 0.504609595484\n",
      "Average accuracy on test set: 0.516259398496\n"
     ]
    }
   ],
   "source": [
    "num_iter = 600\n",
    "acc_train = 0\n",
    "acc_test = 0\n",
    "for m in range(10):\n",
    "    print('start EM number', m)\n",
    "    np.random.seed(m+10)\n",
    "    models, p_z = initialize_dirichlet(K=5, L=3, D=4)\n",
    "    for i in range(num_iter):\n",
    "        models, q_z, p_z = em_dirichlet(X_train, y_train, models, p_z)\n",
    "    print('finish EM.')\n",
    "    train_preds = predict_dirichlet(X_train)\n",
    "    test_preds = predict_dirichlet(X_test)\n",
    "    acc_train += np.mean(train_preds==y_train)\n",
    "    acc_test += np.mean(test_preds==y_test)    \n",
    "    print('Train accuracy:', np.mean(train_preds==y_train))\n",
    "    print('Test accuracy:', np.mean(test_preds==y_test))\n",
    "    print()\n",
    "    \n",
    "print('Average accuracy on training set:', acc_train/10)\n",
    "print('Average accuracy on test set:', acc_test/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
