{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            info = line.strip('\\n').split(',')\n",
    "            X.append([i for i in info[1:]])\n",
    "            y.append(info[0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_in('./hw2_data/mush_train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHOICES = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the values of each feature\n",
    "num_feats = 22\n",
    "feats = {}\n",
    "for i in range(num_feats):\n",
    "    feats[i] = set(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'k', 'b', 'f', 'c', 's', 'x'}, 1: {'y', 'g', 'f', 's'}, 2: {'g', 'w', 'r', 'n', 'y', 'b', 'e', 'c', 'p', 'u'}, 3: {'f', 't'}, 4: {'s', 'l', 'n', 'a', 'y', 'f', 'c', 'p', 'm'}, 5: {'a', 'f'}, 6: {'c', 'w'}, 7: {'n', 'b'}, 8: {'k', 'g', 'w', 'r', 'n', 'b', 'y', 'e', 'o', 'p', 'u', 'h'}, 9: {'e', 't'}, 10: {'r', 'b', 'e', 'c', 'm'}, 11: {'y', 'k', 'f', 's'}, 12: {'y', 'k', 'f', 's'}, 13: {'g', 'w', 'n', 'b', 'y', 'e', 'o', 'c', 'p'}, 14: {'g', 'w', 'n', 'b', 'y', 'e', 'o', 'c', 'p'}, 15: {'p'}, 16: {'n', 'y', 'o', 'w'}, 17: {'o', 'n', 't'}, 18: {'l', 'n', 'e', 'f', 'p'}, 19: {'k', 'w', 'r', 'n', 'b', 'y', 'o', 'u', 'h'}, 20: {'v', 'n', 'a', 'y', 'c', 's'}, 21: {'g', 'd', 'w', 'l', 'p', 'u', 'm'}}\n"
     ]
    }
   ],
   "source": [
    "print(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split a tree demo (using feature X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['f', 'f', 'n'],\n",
       "       ['x', 'y', 'y'],\n",
       "       ['x', 'y', 'n'],\n",
       "       ..., \n",
       "       ['f', 'f', 'n'],\n",
       "       ['x', 'f', 'y'],\n",
       "       ['x', 'f', 'g']], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a starting dict called 'tree'\n",
    "tree = {}\n",
    "tree['predict'] = None\n",
    "tree['X'] = X\n",
    "tree['y'] = y\n",
    "tree['split_feature'] = None\n",
    "tree['remain_feats'] = [i for i in range(X.shape[1])]\n",
    "# tree['remain_feats'] = [i for i in range(3)]\n",
    "tree['children'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "print(tree['remain_feats'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make a split feature to be 0\n",
    "split_feat = 0\n",
    "tree['split_feature'] = 0\n",
    "feat_vals = feats[0]\n",
    "for each in feat_vals:\n",
    "    child = {} # create a child branch\n",
    "    child['predict'] = None # will be updated later\n",
    "    # how to do the recursive algorithm?\n",
    "    child['split_feature'] = None\n",
    "    X_cur = tree['X']\n",
    "    y_cur = tree['y']\n",
    "    child['X'] = X_cur[X_cur[:,split_feat]==each]\n",
    "    child['y'] = y_cur[X_cur[:,split_feat]==each]\n",
    "    # number of remaining features\n",
    "    child['remain_feats'] = list(tree['remain_feats'])\n",
    "    child['remain_feats'].remove(split_feat)\n",
    "    # add to the parent\n",
    "    tree['children'][each] = child\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0791ad6a141b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'remain_feats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 's'"
     ]
    }
   ],
   "source": [
    "print(tree['children']['s']['remain_feats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a recursive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictable(branch):\n",
    "    \"\"\"\n",
    "    Check if a branch in the tree is predictable\n",
    "    (not need to recurse on)\n",
    "    \"\"\"\n",
    "    y = branch['y']\n",
    "    X = branch['X']\n",
    "    if len(set(y)) == 1: # branch is pure\n",
    "        branch['predict'] = y[0]\n",
    "        return True\n",
    "    elif X.shape[0] == 0: # no sample\n",
    "        # what is the prediction in this case?\n",
    "        # just return a random choice\n",
    "        branch['predict'] = random.choice(list(CHOICES))\n",
    "        return True\n",
    "    elif len(branch['remain_feats']) == 0: # no remaining feature \n",
    "        # predict using majority vote\n",
    "        best_choice = None\n",
    "        most_votes = -1\n",
    "        for choice in CHOICES:\n",
    "            cur_vote = np.sum(y == choice)\n",
    "            if cur_vote > most_votes:\n",
    "                most_votes = cur_vote\n",
    "                best_choice = choice\n",
    "        branch['predict'] = best_choice\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_tree(parent, feature_dict):\n",
    "    \"\"\"\n",
    "    Recursive function to expand a tree. \n",
    "    \"\"\"\n",
    "    X_cur = parent['X']\n",
    "    y_cur = parent['y']\n",
    "    # base conditions (probably need a function too)\n",
    "    # print(X_cur)\n",
    "    # print(y_cur)\n",
    "    # print(parent['remain_feats'])\n",
    "    # print(predictable(parent))\n",
    "    # print()\n",
    "    if predictable(parent):\n",
    "        return\n",
    "    # compute split feature (just test random for now)\n",
    "    split_feat = select_feature(y_cur, X_cur, parent['remain_feats'])\n",
    "    parent['split_feature'] = split_feat\n",
    "    feat_vals = feature_dict[split_feat]\n",
    "    for each in feat_vals:\n",
    "        child = {}\n",
    "        child['split_feature'] = None # set it as none as default\n",
    "        # split data based on the feature\n",
    "        child['X'] = X_cur[X_cur[:,split_feat]==each]\n",
    "        child['y'] = y_cur[X_cur[:,split_feat]==each]\n",
    "        #\n",
    "        child['predict'] = None # will be updated later in the recursion\n",
    "        # number of remaining features\n",
    "        child['remain_feats'] = list(parent['remain_feats'])\n",
    "        child['remain_feats'].remove(split_feat)\n",
    "        # link the child to the parent\n",
    "        parent['children'][each] = child\n",
    "        # call the function on children \n",
    "        child['children'] = {}\n",
    "        expand_tree(child, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expand_tree(tree, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# let's try to make a prediction\n",
    "\n",
    "# choices = 'f, y, g'\n",
    "\n",
    "first_feat = tree['split_feature']\n",
    "print(first_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-f130f80b89c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f'"
     ]
    }
   ],
   "source": [
    "first_split = tree['children']['f']\n",
    "print(first_split['predict'])\n",
    "print(first_split['split_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "second_split = first_split['children']['g']\n",
    "print(second_split['predict'])\n",
    "print(second_split['split_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "None\n",
      "90\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "third_split = second_split['children']['y']\n",
    "print(third_split['predict'])\n",
    "print(third_split['split_feature'])\n",
    "y_third = third_split['y']\n",
    "print(np.sum(y_third=='p'))\n",
    "print(np.sum(y_third=='e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_single(x, tree):\n",
    "    \"\"\"\n",
    "    Predict using the decision tree using features in X\n",
    "    (currently single sample). \n",
    "    \"\"\"\n",
    "    prediction = None\n",
    "    subtree = tree\n",
    "    while not prediction:\n",
    "        prediction = subtree['predict']\n",
    "        # print(prediction)\n",
    "        next_split = subtree['split_feature']\n",
    "        # print(next_split)\n",
    "        if next_split != None:\n",
    "            subtree = subtree['children'][x[next_split]]\n",
    "            # print(subtree['predict'])\n",
    "    return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, tree):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        predictions.append(predict_single(X[i,:], tree))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test[5], tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose feature to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability(y):\n",
    "    \"\"\"\n",
    "    Compute a probability table for a variable y.\n",
    "    \"\"\"\n",
    "    choices = set(y)\n",
    "    num_samples = y.shape[0]\n",
    "    prob_dict = {}\n",
    "    for each in choices:\n",
    "        prob_dict[each] = np.sum(y==each) / num_samples\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 0.51655348047538197, 'p': 0.48344651952461798}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Compute entropy.\n",
    "    \"\"\"\n",
    "    prob_dict = probability(y)\n",
    "    result = 0\n",
    "    choices = set(y)\n",
    "    for each in choices:\n",
    "        result -= prob_dict[each]*log_zero(prob_dict[each])\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69259904497005076"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(prob_dict):\n",
    "    \"\"\"\n",
    "    Normalize a probability table.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for each in prob_dict:\n",
    "        total += prob_dict[each]\n",
    "    for each in prob_dict:\n",
    "        prob_dict[each] = prob_dict[each] / total\n",
    "    return prob_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_probability(y, x):\n",
    "    \"\"\"\n",
    "    conditional of y given x\n",
    "    \"\"\"\n",
    "    # obtain probability table for x\n",
    "    prob_x = probability(x)\n",
    "    # compute conditional probability\n",
    "    choices_y = set(y)\n",
    "    choices_x = set(x)\n",
    "    num_samples = y.shape[0]\n",
    "    prob_dict = {}\n",
    "    for each_y in choices_y:\n",
    "        prob_dict[each_y] = {}\n",
    "        for each_x in choices_x:\n",
    "            num_true = 0\n",
    "            for y_cur, x_cur in zip(y, x):\n",
    "                # prob_dict[each_y][each_x] = (np.sum(y==each_y & x==each_x)/num_samples) / prob_x[each_x] \n",
    "                if y_cur == each_y and x_cur == each_x:\n",
    "                    num_true += 1\n",
    "            prob_dict[each_y][each_x] = (num_true/num_samples) / prob_x[each_x]\n",
    "        # normalize\n",
    "        # prob_dict[each_y] = normalize(prob_dict[each_y])\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': {'f': 0.42523118677721472,\n",
       "  'g': 0.0,\n",
       "  's': 0.27324977613864626,\n",
       "  'y': 0.30151903708413913},\n",
       " 'p': {'f': 0.1360060298394184,\n",
       "  'g': 0.41263367876619927,\n",
       "  's': 0.23487521350432544,\n",
       "  'y': 0.21648507789005686}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probability(y, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_zero(number):\n",
    "    if number == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_entropy(y, x):\n",
    "    \"\"\"\n",
    "    Compute conditional entropy.\n",
    "    \"\"\"\n",
    "    prob_x = probability(x)\n",
    "    prob_y_given_x = conditional_probability(y, x)\n",
    "    choices_y = set(y)\n",
    "    choices_x = set(x)   \n",
    "    total = 0\n",
    "    for each_x in choices_x:\n",
    "        for each_y in choices_y:\n",
    "            cur_prob_y_given_x = prob_y_given_x[each_y][each_x]\n",
    "            total -= prob_x[each_x] * cur_prob_y_given_x * log_zero(cur_prob_y_given_x)\n",
    "    return total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67673917732710642"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_entropy(y, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_feature(y, X, possible_features):\n",
    "    \"\"\"\n",
    "    Select the best feature to split in the decision\n",
    "    tree.\n",
    "    \"\"\"\n",
    "    best_info_gain = -1\n",
    "    split_feat = -1\n",
    "    for feat in possible_features:\n",
    "        info_gain = entropy(y) - conditional_entropy(y, X[:,feat])\n",
    "        # print(feat, info_gain)\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            split_feat = feat\n",
    "    return split_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_feat = select_feature(y, X, [i for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(split_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on the small example in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_small = np.array([[1,1], [1,0], [1,1], [1,0], [0,1], [0,0], [0,1], [0,0]])\n",
    "y_small = np.array([1, 1, 1, 1, 1, -1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(select_feature(y_small, X_small, [i for i in range(X_small.shape[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661563238158\n"
     ]
    }
   ],
   "source": [
    "print(entropy(y_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.281167572309\n"
     ]
    }
   ],
   "source": [
    "# should be 0.2811\n",
    "print(conditional_entropy(y_small, X_small[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627741162589\n"
     ]
    }
   ],
   "source": [
    "print(conditional_entropy(y_small, X_small[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {0: 0.25, 1: 1.0}, -1: {0: 0.75, 1: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "print(conditional_probability(y_small, X_small[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = read_in('./hw2_data/mush_test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predict(X_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', np.mean(pred==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/trimcao/Dropbox/Richardson/Fall-2017/cs6375-ml-ruozzi/solution/lib')\n",
    "from DecisionTree import DecisionTree, BoostedTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTree()\n",
    "clf.fit(X, y)\n",
    "clf.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "train_preds = clf.predict(X)\n",
    "print(np.mean(train_preds==y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
