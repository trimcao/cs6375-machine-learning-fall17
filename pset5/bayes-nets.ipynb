{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        not_missing = []\n",
    "        idx = 0\n",
    "        for line in f:\n",
    "            missing = False\n",
    "            info = line.strip('\\n').split(',')\n",
    "            # label is the first column\n",
    "            if info[0] == 'republican':\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "            feature = []\n",
    "            for i in range(1, len(info)):\n",
    "                if info[i] == 'y':\n",
    "                    feature.append(1)\n",
    "                elif info[i] == 'n':\n",
    "                    feature.append(0)\n",
    "                else:\n",
    "                    feature.append(-99)\n",
    "                    missing = True\n",
    "            X.append(feature)\n",
    "            if not missing:\n",
    "                not_missing.append(idx)\n",
    "            idx += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # test using 0 and 1 in this assignment\n",
    "    # y[y=='republican'] = 1\n",
    "    # y[y=='democrat'] = 0\n",
    "    return X, y, np.array(not_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, not_missing = read_in('hw5_data/congress.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((X.shape[0], X.shape[1]+1), dtype=np.int64)\n",
    "data[:,0] = y\n",
    "data[:,1:] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full_data consists of samples with no missing variable.\n",
    "full_data = data[not_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutual_info(X, i, j):\n",
    "    \"\"\"\n",
    "    Compute the mutual information between variable i and j in dataset X. \n",
    "    \"\"\"\n",
    "    values_i = set(X[:,i])\n",
    "    values_j = set(X[:,j])\n",
    "    info = 0\n",
    "    N = X.shape[0] # number of samples\n",
    "    for val_i in values_i:\n",
    "        for val_j in values_j:\n",
    "            idx_i = X[:,i] == val_i\n",
    "            idx_j = X[:,j] == val_j\n",
    "            idx_ij = idx_i & idx_j\n",
    "            info += np.sum(idx_ij)/N * np.log((np.sum(idx_ij)/N) / ((np.sum(idx_i)/N)*(np.sum(idx_j)/N)))\n",
    "            # print(info)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 2\n",
    "a = full_data[:,1] == 0\n",
    "b = full_data[:,2] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021366407572655285"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info(full_data,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021366407572655285"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info(full_data,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chow-Liu Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_vars = full_data.shape[1]\n",
    "graph_matrix = np.zeros((num_vars, num_vars))\n",
    "for i in range(num_vars):\n",
    "    for j in range(num_vars):\n",
    "        if i != j:\n",
    "            info = mutual_info(full_data, i, j)\n",
    "            graph_matrix[i,j] = -info\n",
    "            graph_matrix[j,i] = -info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import minimum_spanning_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = minimum_spanning_tree(graph_matrix).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11\n",
      "1 12\n",
      "2 10\n",
      "3 8\n",
      "4 0\n",
      "4 5\n",
      "5 6\n",
      "5 8\n",
      "5 12\n",
      "5 15\n",
      "7 16\n",
      "8 7\n",
      "9 5\n",
      "13 2\n",
      "13 5\n",
      "14 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_vars):\n",
    "    for j in range(num_vars):\n",
    "        if tree[i,j] != 0:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In E-step, we need to compute a probability distribution for each missing variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, I need to initialize the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = data.shape[1] # number of features\n",
    "N = data.shape[0] # number of samples\n",
    "MISS = -99\n",
    "parents = {0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# missing probabilities\n",
    "b = np.zeros(data.shape[1])\n",
    "for i in range(D):\n",
    "    b[i] = np.sum(data[:,i]==MISS) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model probabilities\n",
    "parent_dict = {0: None, 4: 0, 11: 0, 14: 4, 5: 4, 15: 5, 6: 5, 8: 5, 12: 5,\n",
    "            9: 5, 13: 5, 7: 8, 3: 8, 1: 12, 2: 13, 16: 7, 10: 2}\n",
    "child_dict = {0: {4,11}, 4: {5,14}, 5: {15,6,8,12,9,13}, 8: {7,3}, 7: {16},\n",
    "            13: {2}, 2: {10}, 12: {1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta denotes the parameters of the model, i.e. the conditional probabilities\n",
    "# initialize them with a gaussian random \n",
    "# P(x=1|y=1) = theta[x][1]\n",
    "# note we save only P(x=1|y), P(x=0|y) = 1 - P(x=1|y)\n",
    "theta = {}\n",
    "for child in parent_dict:\n",
    "    theta[child] = {}\n",
    "    for val_parent in range(2):\n",
    "        theta[child][val_parent] = np.random.random()\n",
    "theta[0] = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8694736043573745,\n",
       " 1: {0: 0.7755673551919341, 1: 0.49392062731297326},\n",
       " 2: {0: 0.6249197323851591, 1: 0.385232681467243},\n",
       " 3: {0: 0.8901420108884716, 1: 0.9504120780364718},\n",
       " 4: {0: 0.36386473845098544, 1: 0.4921528718066369},\n",
       " 5: {0: 0.3699313809381112, 1: 0.24314168114980184},\n",
       " 6: {0: 0.2549628440634404, 1: 0.4362803518136984},\n",
       " 7: {0: 0.7011872779668703, 1: 0.9128217478203641},\n",
       " 8: {0: 0.8318112958235429, 1: 0.6424653052580166},\n",
       " 9: {0: 0.7743635360396006, 1: 0.3477978093601367},\n",
       " 10: {0: 0.245384477940079, 1: 0.9572560356679367},\n",
       " 11: {0: 0.7511215419546142, 1: 0.5044032281413467},\n",
       " 12: {0: 0.7167482586280501, 1: 0.7073072392861205},\n",
       " 13: {0: 0.6706400187985302, 1: 0.6039886633925833},\n",
       " 14: {0: 0.12450283073234947, 1: 0.8170253811807481},\n",
       " 15: {0: 0.8091667251633472, 1: 0.23243568670733927},\n",
       " 16: {0: 0.5097811011103777, 1: 0.8525328133843914}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_missing_var_dist(sample, theta):\n",
    "    missing_vars = np.where(sample==MISS)[0]\n",
    "    possible_assigns = list(itertools.product(*[range(2) for i in range(len(missing_vars))]))\n",
    "    prob = prob_non_missing(sample, missing_vars, theta)\n",
    "    q_dist = {var: {} for var in missing_vars} \n",
    "    for var in q_dist:\n",
    "        q_dist[var] = {i: 0 for i in range(2)}\n",
    "\n",
    "    for each_assign in possible_assigns:\n",
    "        current_sample = np.array(sample)\n",
    "        current_sample[missing_vars] = each_assign\n",
    "        #print(current_sample)\n",
    "        # calculate the probability\n",
    "        current_prob = prob\n",
    "        for var in missing_vars:\n",
    "            # add probability P(var|parent(var))\n",
    "            parent_val = current_sample[parent_dict[var]]\n",
    "            if current_sample[var] == 1: \n",
    "                current_prob *= theta[var][parent_val]\n",
    "            else:\n",
    "                current_prob *= 1 - theta[var][parent_val]\n",
    "            # add probability P(child(var)|var)\n",
    "            if var in child_dict:\n",
    "                var_val = current_sample[var]\n",
    "                for each_child in child_dict[var]:\n",
    "                    child_val = current_sample[each_child]\n",
    "                    if child_val == 1:\n",
    "                        current_prob *= theta[each_child][var_val]\n",
    "                    else:\n",
    "                        current_prob *= 1 - theta[each_child][var_val]\n",
    "        # update the q distribution\n",
    "        for i, var in enumerate(missing_vars):\n",
    "            q_dist[var][each_assign[i]] += current_prob\n",
    "\n",
    "    # normalize the q_dist\n",
    "    for var in q_dist:\n",
    "        total = q_dist[var][0] + q_dist[var][1]\n",
    "        q_dist[var][0] /= total\n",
    "        q_dist[var][1] /= total\n",
    "    return q_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_non_missing(sample, missing_vars, theta):\n",
    "    \"\"\"\n",
    "    Compute the probability for non missing variables\n",
    "    \"\"\"\n",
    "    prob = theta[0]\n",
    "    for var in range(1,D):\n",
    "        parent_var = parent_dict[var]\n",
    "        if var not in missing_vars and parent_var not in missing_vars:\n",
    "            parent_val = sample[parent_dict[var]]\n",
    "            if sample[var] == 1:         \n",
    "                prob *= theta[var][parent_val]\n",
    "            else:\n",
    "                prob *= (1 - theta[var][parent_val])\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prob_non_missing() missing 1 required positional argument: 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-c1aa532b08e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmissing_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mMISS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprob_non_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: prob_non_missing() missing 1 required positional argument: 'theta'"
     ]
    }
   ],
   "source": [
    "missing_vars = np.where(data[2]==MISS)[0]\n",
    "prob_non_missing(data[2], missing_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gen_missing_var_dist() missing 1 required positional argument: 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-45f0192b0d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_missing_var_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: gen_missing_var_dist() missing 1 required positional argument: 'theta'"
     ]
    }
   ],
   "source": [
    "gen_missing_var_dist(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_distribution = []\n",
    "for i in range(N):\n",
    "    missing_distribution.append(gen_missing_var_dist(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximization Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.2909177064627031,\n",
       " 1: {0: 0.10592523590107272, 1: 0.5270469684350967},\n",
       " 2: {0: 0.9837656218763154, 1: 0.8952317407403592},\n",
       " 3: {0: 0.48391260053617224, 1: 0.4336635604735033},\n",
       " 4: {0: 0.5578871284767573, 1: 0.6062198928638358},\n",
       " 5: {0: 0.46369778293658026, 1: 0.2652465735126366},\n",
       " 6: {0: 0.8046543066195474, 1: 0.7201388853664181},\n",
       " 7: {0: 0.2134570087249894, 1: 0.9154527546180836},\n",
       " 8: {0: 0.2701472246590333, 1: 0.16472059052856136},\n",
       " 9: {0: 0.7794901943958975, 1: 0.11875560264523766},\n",
       " 10: {0: 0.32612221863362656, 1: 0.0015348474408563018},\n",
       " 11: {0: 0.816703663366438, 1: 0.7068698688730279},\n",
       " 12: {0: 0.8577608722186013, 1: 0.7390014008439103},\n",
       " 13: {0: 0.4175192672257879, 1: 0.5499867175513667},\n",
       " 14: {0: 0.4016183428390353, 1: 0.752276594011051},\n",
       " 15: {0: 0.39650665949871344, 1: 0.7140247815923975},\n",
       " 16: {0: 0.8758973881592609, 1: 0.8875794085781239}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update theta\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to update theta of variable 2 for example\n",
    "theta_up = {}\n",
    "for child in parent_dict:\n",
    "    theta_up[child] = {}\n",
    "    for val_parent in range(2):\n",
    "        theta_up[child][(0,val_parent)] = 0\n",
    "        theta_up[child][(1,val_parent)] = 0\n",
    "\n",
    "theta_up[0] = {}\n",
    "theta_up[0][0] = np.mean(y==0)\n",
    "theta_up[0][1] = 1 - theta_up[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now update theta_up\n",
    "for j, sample in enumerate(data):\n",
    "    # theta_up[0] does not need to be updated\n",
    "    q_dist = missing_distribution[j]\n",
    "    for var in range(1,D):\n",
    "        parent_var = parent_dict[var]\n",
    "        if var in q_dist and parent_var not in q_dist:\n",
    "            val_parent = sample[parent_var]\n",
    "            for val_child in range(2):\n",
    "                theta_up[var][(val_child, val_parent)] += q_dist[var][val_child]\n",
    "        elif var not in q_dist and parent_var in q_dist:\n",
    "            val_child = sample[var]\n",
    "            for val_parent in range(2):\n",
    "                theta_up[var][(val_child, val_parent)] += q_dist[parent_var][val_parent]\n",
    "        elif var in q_dist and parent_var in q_dist:\n",
    "            for val_child in range(2):\n",
    "                for val_parent in range(2):\n",
    "                    theta_up[var][(val_child, val_parent)] += q_dist[var][val_child]*q_dist[parent_var][val_parent]\n",
    "        else:\n",
    "            val_child = sample[var]\n",
    "            val_parent = sample[parent_var]\n",
    "            theta_up[var][(val_child,val_parent)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to normalize theta_up\n",
    "for var in range(1,D):\n",
    "    for val_parent in range(2):\n",
    "        total = theta_up[var][(0,val_parent)] + theta_up[var][(1,val_parent)]\n",
    "        theta_up[var][(0,val_parent)] /= total\n",
    "        theta_up[var][(1,val_parent)] /= total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update theta using theta_up\n",
    "theta[0] = theta_up[0][1]\n",
    "for var in range(1,D):\n",
    "    for val_parent in range(2):\n",
    "        theta[var][val_parent] = theta_up[var][(1,val_parent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximization(data, missing_dist, theta):\n",
    "    \"\"\"\n",
    "    Update the parameters of the model\n",
    "    \"\"\"\n",
    "    # initialize a count dict to count the variables.\n",
    "    count = {}\n",
    "    count[0] = {}\n",
    "    count[0][0] = np.mean(data[:,0]==0)\n",
    "    count[0][1] = 1 - count[0][0]\n",
    "    for var in range(1, D):\n",
    "        count[var] = {}\n",
    "        for val_parent in range(2):\n",
    "            count[var][(0,val_parent)] = 0\n",
    "            count[var][(1,val_parent)] = 0\n",
    "    # print(count)\n",
    "    # update the count using the distribution computed in the E-step\n",
    "    for j, sample in enumerate(data):\n",
    "        q_dist = missing_distribution[j]\n",
    "        for var in range(1,D):\n",
    "            parent_var = parent_dict[var]\n",
    "            if var in q_dist and parent_var not in q_dist:\n",
    "                val_parent = sample[parent_var]\n",
    "                for val_child in range(2):\n",
    "                    count[var][(val_child, val_parent)] += q_dist[var][val_child]\n",
    "            elif var not in q_dist and parent_var in q_dist:\n",
    "                val_child = sample[var]\n",
    "                for val_parent in range(2):\n",
    "                    count[var][(val_child, val_parent)] += q_dist[parent_var][val_parent]\n",
    "            elif var in q_dist and parent_var in q_dist:\n",
    "                for val_child in range(2):\n",
    "                    for val_parent in range(2):\n",
    "                        count[var][(val_child, val_parent)] += q_dist[var][val_child]*q_dist[parent_var][val_parent]\n",
    "            else:\n",
    "                val_child = sample[var]\n",
    "                val_parent = sample[parent_var]\n",
    "                count[var][(val_child,val_parent)] += 1\n",
    "    # normalize the count to get probability distributions\n",
    "    for var in range(1,D):\n",
    "        for val_parent in range(2):\n",
    "            total = count[var][(0,val_parent)] + count[var][(1,val_parent)]\n",
    "            count[var][(0,val_parent)] /= total\n",
    "            count[var][(1,val_parent)] /= total \n",
    "    \n",
    "    # update theta using theta_up\n",
    "    theta[0] = count[0][1]\n",
    "    for var in range(1,D):\n",
    "        for val_parent in range(2):\n",
    "            theta[var][val_parent] = count[var][(1,val_parent)]\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = maximization(data, missing_distribution, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.38620689655172413,\n",
       " 1: {0: 0.6008708208274086, 1: 0.24274581072001897},\n",
       " 2: {0: 0.43229096340931483, 1: 0.599125209210905},\n",
       " 3: {0: 0.21071323860190072, 1: 0.8902434732585263},\n",
       " 4: {0: 0.06894679113226365, 1: 0.9816817530172026},\n",
       " 5: {0: 0.18673563871823387, 1: 0.9278888812895361},\n",
       " 6: {0: 0.35878762062694197, 1: 0.9357156057172461},\n",
       " 7: {0: 0.15303882113774459, 1: 0.884255133066244},\n",
       " 8: {0: 0.9693096794910533, 1: 0.15489908524380214},\n",
       " 9: {0: 0.9019803128492735, 1: 0.10541680712722212},\n",
       " 10: {0: 0.6050905404163758, 1: 0.3998007344137381},\n",
       " 11: {0: 0.5198518500389411, 1: 0.1628680286896265},\n",
       " 12: {0: 0.16110066487981647, 1: 0.7430563085522784},\n",
       " 13: {0: 0.19900492161070144, 1: 0.8262186183015763},\n",
       " 14: {0: 0.32259529008755766, 1: 0.9638602538165654},\n",
       " 15: {0: 0.6906512504912588, 1: 0.17835389452275507},\n",
       " 16: {0: 0.6605294542366618, 1: 0.9638268868061921}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = data.shape[1] # number of features\n",
    "N = data.shape[0] # number of samples\n",
    "MISS = -99\n",
    "parents = {0}\n",
    "# missing probabilities\n",
    "b = np.zeros(data.shape[1])\n",
    "for i in range(D):\n",
    "    b[i] = np.sum(data[:,i]==MISS) / N \n",
    "# parent and child dicts\n",
    "parent_dict = {0: None, 4: 0, 11: 0, 14: 4, 5: 4, 15: 5, 6: 5, 8: 5, 12: 5,\n",
    "            9: 5, 13: 5, 7: 8, 3: 8, 1: 12, 2: 13, 16: 7, 10: 2}\n",
    "child_dict = {0: {4,11}, 4: {5,14}, 5: {15,6,8,12,9,13}, 8: {7,3}, 7: {16},\n",
    "            13: {2}, 2: {10}, 12: {1}}\n",
    "# initialize model probabilities\n",
    "np.random.seed(0)\n",
    "theta = {}\n",
    "theta[0] = np.random.random()\n",
    "for var in range(1,D):\n",
    "    theta[var] = {}\n",
    "    for val_parent in range(2):\n",
    "        theta[var][val_parent] = np.random.random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{0: 0.6136767186533647, 1: 0.22538625550099786}\n",
      "1\n",
      "{0: 0.62575930644073618, 1: 0.19439469828462452}\n",
      "2\n",
      "{0: 0.62717746644541383, 1: 0.19273821864090263}\n",
      "3\n",
      "{0: 0.6272831967008351, 1: 0.1926539913254085}\n",
      "4\n",
      "{0: 0.62729012048525112, 1: 0.19264961868762775}\n",
      "5\n",
      "{0: 0.62729054043664045, 1: 0.19264943716917934}\n",
      "6\n",
      "{0: 0.62729056274592365, 1: 0.19264944617613833}\n",
      "7\n",
      "{0: 0.62729056325408483, 1: 0.19264945215265739}\n",
      "8\n",
      "{0: 0.62729056306584918, 1: 0.19264945399509886}\n",
      "9\n",
      "{0: 0.6272905629961244, 1: 0.19264945450917292}\n"
     ]
    }
   ],
   "source": [
    "num_iters = 10\n",
    "for i in range(num_iters):\n",
    "    print(i)\n",
    "    # E-step\n",
    "    missing_distribution = []\n",
    "    for i in range(N):\n",
    "        missing_distribution.append(gen_missing_var_dist(data[i], theta))\n",
    "    # M-step\n",
    "    theta = maximization(data, missing_distribution, theta)\n",
    "    print(theta[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.38620689655172413,\n",
       " 1: {0: 0.6272905629961244, 1: 0.19264945450917292},\n",
       " 2: {0: 0.37825460974094732, 1: 0.62358528994857221},\n",
       " 3: {0: 0.19631725868918934, 1: 0.89981069117926471},\n",
       " 4: {0: 0.056345201033663084, 1: 0.98250028763911545},\n",
       " 5: {0: 0.18453846128275811, 1: 0.95490094821711968},\n",
       " 6: {0: 0.33305796916773489, 1: 0.93993323113544458},\n",
       " 7: {0: 0.14248205342185821, 1: 0.88733010572916704},\n",
       " 8: {0: 0.99040569553144631, 1: 0.14752160830839706},\n",
       " 9: {0: 0.91605795430241743, 1: 0.099531286619424744},\n",
       " 10: {0: 0.56800381002659139, 1: 0.44318048393889514},\n",
       " 11: {0: 0.50588235294118644, 1: 0.13207547169817735},\n",
       " 12: {0: 0.097806799890551896, 1: 0.74400409731855699},\n",
       " 13: {0: 0.17189576896238146, 1: 0.84736885294283026},\n",
       " 14: {0: 0.31752043023283621, 1: 0.98196814210418015},\n",
       " 15: {0: 0.71984749771831302, 1: 0.13633598982683554},\n",
       " 16: {0: 0.61352628241891205, 1: 0.99320516122383584}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5434049417909654,\n",
       " 1: {0: 0.27836938509379616, 1: 0.4245175907491331},\n",
       " 2: {0: 0.8447761323199037, 1: 0.004718856190972565},\n",
       " 3: {0: 0.12156912078311422, 1: 0.6707490847267786},\n",
       " 4: {0: 0.8258527551050476, 1: 0.13670658968495297},\n",
       " 5: {0: 0.57509332942725, 1: 0.891321954312264},\n",
       " 6: {0: 0.20920212211718958, 1: 0.18532821955007506},\n",
       " 7: {0: 0.10837689046425514, 1: 0.21969749262499216},\n",
       " 8: {0: 0.9786237847073697, 1: 0.8116831490893233},\n",
       " 9: {0: 0.1719410127325942, 1: 0.8162247487258399},\n",
       " 10: {0: 0.2740737470416992, 1: 0.4317041836631217},\n",
       " 11: {0: 0.9400298196223746, 1: 0.8176493787767274},\n",
       " 12: {0: 0.3361119501208987, 1: 0.17541045374233666},\n",
       " 13: {0: 0.37283204628992317, 1: 0.005688507352573424},\n",
       " 14: {0: 0.25242635344484043, 1: 0.7956625084732873},\n",
       " 15: {0: 0.01525497124633901, 1: 0.5988433769284929},\n",
       " 16: {0: 0.6038045390428536, 1: 0.10514768541205632}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model probabilities\n",
    "np.random.seed(100)\n",
    "theta = {}\n",
    "theta[0] = np.random.random()\n",
    "for var in range(1,D):\n",
    "    theta[var] = {}\n",
    "    for val_parent in range(2):\n",
    "        theta[var][val_parent] = np.random.random()\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{0: 0.5945078561526554, 1: 0.21173325379824082}\n",
      "1\n",
      "{0: 0.62485894237331308, 1: 0.19354967527335856}\n",
      "2\n",
      "{0: 0.62713470487756251, 1: 0.19268360480475047}\n",
      "3\n",
      "{0: 0.62728111441909884, 1: 0.1926500313194765}\n",
      "4\n",
      "{0: 0.62729002111305121, 1: 0.19264928135624998}\n",
      "5\n",
      "{0: 0.62729053697540971, 1: 0.19264939851915869}\n",
      "6\n",
      "{0: 0.62729056305879316, 1: 0.19264943958511729}\n",
      "7\n",
      "{0: 0.62729056341471523, 1: 0.19264945065330263}\n",
      "8\n",
      "{0: 0.62729056311532394, 1: 0.19264945360914146}\n",
      "9\n",
      "{0: 0.62729056301018415, 1: 0.19264945440575335}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.38620689655172413,\n",
       " 1: {0: 0.62729056301018415, 1: 0.19264945440575335},\n",
       " 2: {0: 0.37825461267532012, 1: 0.62358528940837166},\n",
       " 3: {0: 0.19631725428914107, 1: 0.89981069518436452},\n",
       " 4: {0: 0.056345201247827589, 1: 0.98250028810645218},\n",
       " 5: {0: 0.18453846128489093, 1: 0.95490094850421414},\n",
       " 6: {0: 0.33305796918195751, 1: 0.93993323129918027},\n",
       " 7: {0: 0.14248204864717559, 1: 0.88733010321545525},\n",
       " 8: {0: 0.99040569560097413, 1: 0.14752160279823301},\n",
       " 9: {0: 0.91605795477387397, 1: 0.099531286364177449},\n",
       " 10: {0: 0.56800381120723176, 1: 0.44318048308354313},\n",
       " 11: {0: 0.50588235294119088, 1: 0.13207547169824668},\n",
       " 12: {0: 0.09780679978782103, 1: 0.74400409769585185},\n",
       " 13: {0: 0.17189576869811832, 1: 0.8473688530212472},\n",
       " 14: {0: 0.31752043019976628, 1: 0.98196814211735339},\n",
       " 15: {0: 0.7198474977007252, 1: 0.13633598955550796},\n",
       " 16: {0: 0.61352629929805669, 1: 0.99320443504955158}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iters = 10\n",
    "for i in range(num_iters):\n",
    "    print(i)\n",
    "    # E-step\n",
    "    missing_distribution = []\n",
    "    for i in range(N):\n",
    "        missing_distribution.append(gen_missing_var_dist(data[i], theta))\n",
    "    # M-step\n",
    "    theta = maximization(data, missing_distribution, theta)\n",
    "    print(theta[1])\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{0: 0.38620689655172413,\n",
    " 1: {0: 0.6272905629961244, 1: 0.19264945450917292},\n",
    " 2: {0: 0.37825460974094732, 1: 0.62358528994857221},\n",
    " 3: {0: 0.19631725868918934, 1: 0.89981069117926471},\n",
    " 4: {0: 0.056345201033663084, 1: 0.98250028763911545},\n",
    " 5: {0: 0.18453846128275811, 1: 0.95490094821711968},\n",
    " 6: {0: 0.33305796916773489, 1: 0.93993323113544458},\n",
    " 7: {0: 0.14248205342185821, 1: 0.88733010572916704},\n",
    " 8: {0: 0.99040569553144631, 1: 0.14752160830839706},\n",
    " 9: {0: 0.91605795430241743, 1: 0.099531286619424744},\n",
    " 10: {0: 0.56800381002659139, 1: 0.44318048393889514},\n",
    " 11: {0: 0.50588235294118644, 1: 0.13207547169817735},\n",
    " 12: {0: 0.097806799890551896, 1: 0.74400409731855699},\n",
    " 13: {0: 0.17189576896238146, 1: 0.84736885294283026},\n",
    " 14: {0: 0.31752043023283621, 1: 0.98196814210418015},\n",
    " 15: {0: 0.71984749771831302, 1: 0.13633598982683554},\n",
    " 16: {0: 0.61352628241891205, 1: 0.99320516122383584}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{0: 0.5970845505267366, 1: 0.22445937034599997}\n",
      "1\n",
      "{0: 0.62503891390647726, 1: 0.19470753535421428}\n",
      "2\n",
      "{0: 0.627139868185278, 1: 0.1927764940938631}\n",
      "3\n",
      "{0: 0.62728091392814633, 1: 0.19265761980343546}\n",
      "4\n",
      "{0: 0.62728996087539257, 1: 0.19264997329473518}\n",
      "5\n",
      "{0: 0.62729052684549347, 1: 0.19264947973639768}\n",
      "6\n",
      "{0: 0.62729056115149706, 1: 0.19264945320236446}\n",
      "7\n",
      "{0: 0.62729056298214125, 1: 0.19264945366734051}\n",
      "8\n",
      "{0: 0.62729056300579789, 1: 0.19264945436996966}\n",
      "9\n",
      "{0: 0.62729056298119068, 1: 0.19264945460719479}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.38620689655172413,\n",
       " 1: {0: 0.62729056298119068, 1: 0.19264945460719479},\n",
       " 2: {0: 0.37825461007786793, 1: 0.62358528961547643},\n",
       " 3: {0: 0.19631726292740803, 1: 0.89981068731425884},\n",
       " 4: {0: 0.056345200827605503, 1: 0.98250028718875715},\n",
       " 5: {0: 0.18453846128691842, 1: 0.9549009479490117},\n",
       " 6: {0: 0.33305796915007135, 1: 0.93993323097969184},\n",
       " 7: {0: 0.14248205868900932, 1: 0.88733010825245273},\n",
       " 8: {0: 0.99040569546550605, 1: 0.1475216135889322},\n",
       " 9: {0: 0.91605795385235456, 1: 0.099531286866340801},\n",
       " 10: {0: 0.56800381020026813, 1: 0.44318048384040926},\n",
       " 11: {0: 0.50588235294117367, 1: 0.13207547169816536},\n",
       " 12: {0: 0.097806799990425825, 1: 0.74400409695069514},\n",
       " 13: {0: 0.1718957689376652, 1: 0.84736885265515816},\n",
       " 14: {0: 0.31752043026295584, 1: 0.98196814210266481},\n",
       " 15: {0: 0.71984749773905954, 1: 0.13633599008792854},\n",
       " 16: {0: 0.61352621956915798, 1: 0.99320581987332257}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model probabilities\n",
    "np.random.seed(300)\n",
    "theta = {}\n",
    "theta[0] = np.random.random()\n",
    "for var in range(1,D):\n",
    "    theta[var] = {}\n",
    "    for val_parent in range(2):\n",
    "        theta[var][val_parent] = np.random.random()\n",
    "        \n",
    "num_iters = 10\n",
    "for i in range(num_iters):\n",
    "    print(i)\n",
    "    # E-step\n",
    "    missing_distribution = []\n",
    "    for i in range(N):\n",
    "        missing_distribution.append(gen_missing_var_dist(data[i], theta))\n",
    "    # M-step\n",
    "    theta = maximization(data, missing_distribution, theta)\n",
    "    print(theta[1])\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
